{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import seaborn           as sns\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from imutils        import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils  import shuffle\n",
    "from urllib.request import urlopen\n",
    "from sklearn.decomposition import PCA\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models              import Sequential\n",
    "from tensorflow.keras.preprocessing       import image\n",
    "from tensorflow.keras.utils               import to_categorical\n",
    "from tensorflow.keras.callbacks           import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers              import Conv2D,Flatten,MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img,array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2012_004107_jpg.rf.514479ee455502d126b4540aada33375.jpg\n",
      "Nesneler: [{'class_name': 'person', 'bbox': [67, 57, 367, 359]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2010_001699_jpg.rf.519e087484ecf63279b7fc8020b61f0b.jpg\n",
      "Nesneler: [{'class_name': 'person', 'bbox': [269, 90, 419, 374]}, {'class_name': 'chair', 'bbox': [257, 83, 420, 357]}, {'class_name': 'pottedplant', 'bbox': [455, 99, 499, 168]}, {'class_name': 'pottedplant', 'bbox': [198, 17, 409, 157]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2010_002044_jpg.rf.51259121f651a2a5c18927fddc306371.jpg\n",
      "Nesneler: [{'class_name': 'car', 'bbox': [37, 29, 471, 327]}, {'class_name': 'car', 'bbox': [398, 77, 499, 242]}, {'class_name': 'person', 'bbox': [62, 9, 92, 120]}, {'class_name': 'person', 'bbox': [197, 12, 221, 42]}, {'class_name': 'person', 'bbox': [191, 94, 214, 178]}, {'class_name': 'person', 'bbox': [220, 79, 290, 163]}, {'class_name': 'person', 'bbox': [350, 68, 438, 132]}, {'class_name': 'person', 'bbox': [362, 33, 404, 86]}, {'class_name': 'person', 'bbox': [482, 55, 496, 99]}, {'class_name': 'person', 'bbox': [449, 112, 499, 372]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2011_004402_jpg.rf.519dd3ed0c97bc7a22c46d378960d545.jpg\n",
      "Nesneler: [{'class_name': 'person', 'bbox': [162, 0, 406, 374]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2012_003955_jpg.rf.513ddf2851cf6bcc2ced2a08b065fc93.jpg\n",
      "Nesneler: [{'class_name': 'person', 'bbox': [254, 37, 375, 444]}, {'class_name': 'person', 'bbox': [150, 34, 289, 447]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2012_000115_jpg.rf.51258217e25f5e019436e86d15307fb1.jpg\n",
      "Nesneler: [{'class_name': 'person', 'bbox': [18, 24, 420, 448]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2008_005882_jpg.rf.519ad7f877063128e945a2bf576014b2.jpg\n",
      "Nesneler: [{'class_name': 'dog', 'bbox': [193, 135, 390, 257]}, {'class_name': 'cat', 'bbox': [82, 184, 217, 270]}, {'class_name': 'sofa', 'bbox': [0, 74, 485, 374]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2010_006902_jpg.rf.514060187fcce9eaa53dee6eb1b35c37.jpg\n",
      "Nesneler: [{'class_name': 'person', 'bbox': [112, 136, 208, 421]}, {'class_name': 'person', 'bbox': [53, 171, 122, 357]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2010_000647_jpg.rf.518e1087e3633bc9d7c3661dd4f8786c.jpg\n",
      "Nesneler: [{'class_name': 'cat', 'bbox': [28, 173, 280, 333]}, {'class_name': 'person', 'bbox': [45, 17, 486, 499]}]\n",
      "Görsel: Pascal_VOC_2012_Dataset\\train\\2012_001129_jpg.rf.5198d60d523995e6efb50405c2018971.jpg\n",
      "Nesneler: [{'class_name': 'person', 'bbox': [74, 38, 173, 256]}, {'class_name': 'person', 'bbox': [191, 36, 277, 255]}, {'class_name': 'person', 'bbox': [309, 21, 394, 263]}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Veri seti yolu\n",
    "dataset_path = \"Pascal_VOC_2012_Dataset\"\n",
    "train_annotations_path = os.path.join(dataset_path, \"train\", \"_annotations.coco.json\")\n",
    "\n",
    "# COCO formatındaki JSON'u oku\n",
    "with open(train_annotations_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# ID'den kategori ismi eşlemesi oluştur\n",
    "categories = {cat[\"id\"]: cat[\"name\"] for cat in data[\"categories\"]}\n",
    "\n",
    "# İlk 10 görsel ve etiketleri yazdır\n",
    "for image_info in data[\"images\"][:10]:\n",
    "    image_id = image_info[\"id\"]\n",
    "    image_path = os.path.join(dataset_path, \"train\", image_info[\"file_name\"])\n",
    "\n",
    "    # Bu görsele ait annotation'ları bul\n",
    "    annotations = [ann for ann in data[\"annotations\"] if ann[\"image_id\"] == image_id]\n",
    "\n",
    "    objects = []\n",
    "    for ann in annotations:\n",
    "        class_name = categories[ann[\"category_id\"]]\n",
    "        bbox = ann[\"bbox\"]  # COCO formatı [x, y, width, height]\n",
    "        xmin, ymin, width, height = bbox\n",
    "        xmax = xmin + width\n",
    "        ymax = ymin + height\n",
    "\n",
    "        objects.append({\n",
    "            \"class_name\": class_name,\n",
    "            \"bbox\": [xmin, ymin, xmax, ymax]\n",
    "        })\n",
    "\n",
    "    print(f\"Görsel: {image_path}\")\n",
    "    print(\"Nesneler:\", objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Sistem belirtilen yolu bulamıyor: 'pascal-voc-2012\\\\Annotations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_path, objects\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# İlk 10 veriyi gösterelim\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xml_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotation_dir\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m10\u001b[39m]:\n\u001b[0;32m     43\u001b[0m     xml_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(annotation_dir, xml_file)\n\u001b[0;32m     44\u001b[0m     image_path, objects \u001b[38;5;241m=\u001b[39m parse_xml(xml_path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Sistem belirtilen yolu bulamıyor: 'pascal-voc-2012\\\\Annotations'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "# Veri seti dizini\n",
    "dataset_path = \"pascal-voc-2012\"\n",
    "image_dir = os.path.join(dataset_path, \"JPEGImages\")\n",
    "annotation_dir = os.path.join(dataset_path, \"Annotations\")\n",
    "\n",
    "# Sınıf etiketleri\n",
    "class_names = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
    "               \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "               \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "               \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# XML'i TensorFlow için uygun hale getirme\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find(\"filename\").text\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "    objects = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bbox.find(\"xmin\").text)\n",
    "        ymin = int(bbox.find(\"ymin\").text)\n",
    "        xmax = int(bbox.find(\"xmax\").text)\n",
    "        ymax = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "        objects.append({\n",
    "            \"class_name\": class_name,\n",
    "            \"bbox\": [xmin, ymin, xmax, ymax]\n",
    "        })\n",
    "\n",
    "    return image_path, objects\n",
    "\n",
    "# İlk 10 veriyi gösterelim\n",
    "for xml_file in os.listdir(annotation_dir)[:10]:\n",
    "    xml_path = os.path.join(annotation_dir, xml_file)\n",
    "    image_path, objects = parse_xml(xml_path)\n",
    "    print(f\"Görsel: {image_path}\")\n",
    "    print(\"Nesneler:\", objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "\n",
    "# TensorFlow veri kümesi oluşturma fonksiyonu\n",
    "def load_data():\n",
    "    images, bboxes, labels = [], [], []\n",
    "\n",
    "    for xml_file in os.listdir(annotation_dir):\n",
    "        xml_path = os.path.join(annotation_dir, xml_file)\n",
    "        image_path, objects = parse_xml(xml_path)\n",
    "\n",
    "        # Görseli yükle ve normalize et\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224)) / 255.0  # Normalize et\n",
    "\n",
    "        images.append(image)\n",
    "        boxes = []\n",
    "        classes = []\n",
    "\n",
    "        for obj in objects:\n",
    "            bbox = obj[\"bbox\"]\n",
    "            class_index = class_names.index(obj[\"class_name\"])  # Sınıfı indeksle\n",
    "            boxes.append(bbox)\n",
    "            classes.append(class_index)\n",
    "\n",
    "        bboxes.append(boxes)\n",
    "        labels.append(classes)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((images, bboxes, labels))\n",
    "\n",
    "# Dataseti yükleyelim\n",
    "dataset = load_data()\n",
    "print(\"Dataset başarıyla oluşturuldu!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\n",
    "\n",
    "# Feature Extractor CNN - Sıfırdan\n",
    "def create_feature_extractor():\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, x, name=\"Feature_Extractor\")\n",
    "    return model\n",
    "\n",
    "feature_extractor = create_feature_extractor()\n",
    "feature_extractor.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "def create_rpn(feature_map):\n",
    "    x = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(feature_map)\n",
    "    objectness_score = Conv2D(1, (1, 1), activation=\"sigmoid\")(x)  # Nesne olup olmadığını tahmin eder\n",
    "    bbox_regression = Conv2D(4, (1, 1), activation=\"linear\")(x)  # Bounding Box koordinatlarını öğrenir\n",
    "    return objectness_score, bbox_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_head(feature_map):\n",
    "    x = Dense(512, activation=\"relu\")(feature_map)\n",
    "    class_output = Dense(len(class_names), activation=\"softmax\", name=\"class_output\")(x)\n",
    "    bbox_output = Dense(4, activation=\"linear\", name=\"bbox_output\")(x)\n",
    "    return class_output, bbox_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faster_rcnn():\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    # 1️⃣ Feature Extraction\n",
    "    feature_map = create_feature_extractor()(inputs)\n",
    "\n",
    "    # 2️⃣ Region Proposal Network (RPN)\n",
    "    objectness_score, bbox_regression = create_rpn(feature_map)\n",
    "\n",
    "    # 3️⃣ R-CNN Head (Sınıflandırıcı + Bounding Box)\n",
    "    class_output, final_bbox = create_rcnn_head(feature_map)\n",
    "\n",
    "    # Modeli birleştirme\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[class_output, final_bbox, objectness_score, bbox_regression])\n",
    "    model.compile(loss=[\"sparse_categorical_crossentropy\", \"mse\", \"binary_crossentropy\", \"mse\"], \n",
    "                  optimizer=\"adam\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Modeli oluştur\n",
    "faster_rcnn = create_faster_rcnn()\n",
    "faster_rcnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli eğitme\n",
    "faster_rcnn.fit(dataset.batch(32), epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test için bir görsel al\n",
    "test_image, test_bbox, test_label = next(iter(dataset))\n",
    "\n",
    "# Model ile tahmin yap\n",
    "pred_class, pred_bbox, obj_score, bbox_reg = faster_rcnn.predict(np.expand_dims(test_image, axis=0))\n",
    "\n",
    "print(\"Tahmin edilen sınıf:\", class_names[np.argmax(pred_class)])\n",
    "print(\"Tahmin edilen bounding box:\", pred_bbox)\n",
    "print(\"Nesne skoru:\", obj_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
