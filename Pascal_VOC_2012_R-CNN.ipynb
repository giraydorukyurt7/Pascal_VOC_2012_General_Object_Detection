{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import seaborn           as sns\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from imutils        import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils  import shuffle\n",
    "from urllib.request import urlopen\n",
    "from sklearn.decomposition import PCA\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models              import Sequential\n",
    "from tensorflow.keras.preprocessing       import image\n",
    "from tensorflow.keras.utils               import to_categorical\n",
    "from tensorflow.keras.callbacks           import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers              import Conv2D,Flatten,MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img,array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "# Veri seti dizini\n",
    "dataset_path = \"pascal-voc-2012\"\n",
    "image_dir = os.path.join(dataset_path, \"JPEGImages\")\n",
    "annotation_dir = os.path.join(dataset_path, \"Annotations\")\n",
    "\n",
    "# Sınıf etiketleri\n",
    "class_names = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
    "               \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "               \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "               \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# XML'i TensorFlow için uygun hale getirme\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find(\"filename\").text\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "    objects = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bbox.find(\"xmin\").text)\n",
    "        ymin = int(bbox.find(\"ymin\").text)\n",
    "        xmax = int(bbox.find(\"xmax\").text)\n",
    "        ymax = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "        objects.append({\n",
    "            \"class_name\": class_name,\n",
    "            \"bbox\": [xmin, ymin, xmax, ymax]\n",
    "        })\n",
    "\n",
    "    return image_path, objects\n",
    "\n",
    "# İlk 10 veriyi gösterelim\n",
    "for xml_file in os.listdir(annotation_dir)[:10]:\n",
    "    xml_path = os.path.join(annotation_dir, xml_file)\n",
    "    image_path, objects = parse_xml(xml_path)\n",
    "    print(f\"Görsel: {image_path}\")\n",
    "    print(\"Nesneler:\", objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "\n",
    "# Veri seti dizini\n",
    "dataset_path = \"pascal-voc-2012\"\n",
    "image_dir = os.path.join(dataset_path, \"JPEGImages\")\n",
    "annotation_dir = os.path.join(dataset_path, \"Annotations\")\n",
    "\n",
    "# Sınıf etiketleri\n",
    "class_names = [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\",\n",
    "               \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "               \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "               \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# XML'i TensorFlow için uygun hale getirme\n",
    "def parse_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    filename = root.find(\"filename\").text\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "\n",
    "    objects = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin = int(bbox.find(\"xmin\").text)\n",
    "        ymin = int(bbox.find(\"ymin\").text)\n",
    "        xmax = int(bbox.find(\"xmax\").text)\n",
    "        ymax = int(bbox.find(\"ymax\").text)\n",
    "\n",
    "        objects.append({\n",
    "            \"class_name\": class_name,\n",
    "            \"bbox\": [xmin, ymin, xmax, ymax]\n",
    "        })\n",
    "\n",
    "    return image_path, objects\n",
    "\n",
    "# İlk 10 veriyi gösterelim\n",
    "for xml_file in os.listdir(annotation_dir)[:10]:\n",
    "    xml_path = os.path.join(annotation_dir, xml_file)\n",
    "    image_path, objects = parse_xml(xml_path)\n",
    "    print(f\"Görsel: {image_path}\")\n",
    "    print(\"Nesneler:\", objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "\n",
    "# TensorFlow veri kümesi oluşturma fonksiyonu\n",
    "def load_data():\n",
    "    images, bboxes, labels = [], [], []\n",
    "\n",
    "    for xml_file in os.listdir(annotation_dir):\n",
    "        xml_path = os.path.join(annotation_dir, xml_file)\n",
    "        image_path, objects = parse_xml(xml_path)\n",
    "\n",
    "        # Görseli yükle ve normalize et\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224)) / 255.0  # Normalize et\n",
    "\n",
    "        images.append(image)\n",
    "        boxes = []\n",
    "        classes = []\n",
    "\n",
    "        for obj in objects:\n",
    "            bbox = obj[\"bbox\"]\n",
    "            class_index = class_names.index(obj[\"class_name\"])  # Sınıfı indeksle\n",
    "            boxes.append(bbox)\n",
    "            classes.append(class_index)\n",
    "\n",
    "        bboxes.append(boxes)\n",
    "        labels.append(classes)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((images, bboxes, labels))\n",
    "\n",
    "# Dataseti yükleyelim\n",
    "dataset = load_data()\n",
    "print(\"Dataset başarıyla oluşturuldu!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
    "\n",
    "# Feature Extractor CNN - Sıfırdan\n",
    "def create_feature_extractor():\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, x, name=\"Feature_Extractor\")\n",
    "    return model\n",
    "\n",
    "feature_extractor = create_feature_extractor()\n",
    "feature_extractor.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "def create_rpn(feature_map):\n",
    "    x = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(feature_map)\n",
    "    objectness_score = Conv2D(1, (1, 1), activation=\"sigmoid\")(x)  # Nesne olup olmadığını tahmin eder\n",
    "    bbox_regression = Conv2D(4, (1, 1), activation=\"linear\")(x)  # Bounding Box koordinatlarını öğrenir\n",
    "    return objectness_score, bbox_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn_head(feature_map):\n",
    "    x = Dense(512, activation=\"relu\")(feature_map)\n",
    "    class_output = Dense(len(class_names), activation=\"softmax\", name=\"class_output\")(x)\n",
    "    bbox_output = Dense(4, activation=\"linear\", name=\"bbox_output\")(x)\n",
    "    return class_output, bbox_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faster_rcnn():\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    # 1️⃣ Feature Extraction\n",
    "    feature_map = create_feature_extractor()(inputs)\n",
    "\n",
    "    # 2️⃣ Region Proposal Network (RPN)\n",
    "    objectness_score, bbox_regression = create_rpn(feature_map)\n",
    "\n",
    "    # 3️⃣ R-CNN Head (Sınıflandırıcı + Bounding Box)\n",
    "    class_output, final_bbox = create_rcnn_head(feature_map)\n",
    "\n",
    "    # Modeli birleştirme\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[class_output, final_bbox, objectness_score, bbox_regression])\n",
    "    model.compile(loss=[\"sparse_categorical_crossentropy\", \"mse\", \"binary_crossentropy\", \"mse\"], \n",
    "                  optimizer=\"adam\", \n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Modeli oluştur\n",
    "faster_rcnn = create_faster_rcnn()\n",
    "faster_rcnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli eğitme\n",
    "faster_rcnn.fit(dataset.batch(32), epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test için bir görsel al\n",
    "test_image, test_bbox, test_label = next(iter(dataset))\n",
    "\n",
    "# Model ile tahmin yap\n",
    "pred_class, pred_bbox, obj_score, bbox_reg = faster_rcnn.predict(np.expand_dims(test_image, axis=0))\n",
    "\n",
    "print(\"Tahmin edilen sınıf:\", class_names[np.argmax(pred_class)])\n",
    "print(\"Tahmin edilen bounding box:\", pred_bbox)\n",
    "print(\"Nesne skoru:\", obj_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
